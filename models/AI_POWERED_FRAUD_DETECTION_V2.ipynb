{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ‚≠ê TRAINING NOTEBOOK v6 (FINAL PRODUCTION VERSION)\n",
        "# Synthetic fraud engine aligned with app.py / fraud_logic.py\n",
        "# ============================================================\n",
        "\n",
        "# ============================================\n",
        "# Cell 1: Imports & configuration\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    precision_recall_curve,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import joblib\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Where to save models (compatible with app)\n",
        "MODELS_DIR = \"models\"\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "supervised_path = os.path.join(MODELS_DIR, \"supervised_lgbm_pipeline.joblib\")\n",
        "iforest_path = os.path.join(MODELS_DIR, \"iforest_pipeline.joblib\")\n",
        "thresholds_path = os.path.join(MODELS_DIR, \"model_thresholds.json\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Cell 2: Synthetic data helpers\n",
        "# ============================================\n",
        "\n",
        "# Channels aligned with your app\n",
        "CHANNELS = [\n",
        "    \"Mobile App\",\n",
        "    \"NetBanking\",\n",
        "    \"ATM\",\n",
        "    \"POS\",\n",
        "    \"Online Purchase\",\n",
        "    \"UPI\",\n",
        "    \"Credit Card\",\n",
        "    \"Debit Card\",\n",
        "    \"Branch\",\n",
        "]\n",
        "\n",
        "TRANSACTION_TYPES = [\"PAYMENT\", \"TRANSFER\", \"WITHDRAWAL\", \"BILL_PAY\"]\n",
        "\n",
        "CITIES_NORMAL = [\n",
        "    \"Mumbai\",\n",
        "    \"Bangalore\",\n",
        "    \"Delhi\",\n",
        "    \"Chennai\",\n",
        "    \"Hyderabad\",\n",
        "    \"Pune\",\n",
        "    \"Kolkata\",\n",
        "]\n",
        "\n",
        "CITIES_HIGH_RISK = [\n",
        "    \"Lagos\",\n",
        "    \"Karachi\",\n",
        "    \"Nairobi\",\n",
        "    \"Bogota\",\n",
        "]\n",
        "\n",
        "ALL_CITIES = CITIES_NORMAL + CITIES_HIGH_RISK\n",
        "\n",
        "COUNTRIES_NORMAL = [\"India\", \"USA\", \"UK\"]\n",
        "COUNTRIES_HIGH_RISK = [\"Nigeria\", \"Pakistan\", \"Colombia\"]\n",
        "\n",
        "DEVICES = [\n",
        "    \"MOB-ANDROID\",\n",
        "    \"MOB-IOS\",\n",
        "    \"WEB-CHROME\",\n",
        "    \"WEB-SAFARI\",\n",
        "    \"POS-TERM-001\",\n",
        "    \"POS-TERM-002\",\n",
        "    \"ATM-0001\",\n",
        "    \"ATM-0002\",\n",
        "    \"BANK-CSR\",\n",
        "]\n",
        "\n",
        "def sample_hours(size, fraud=False):\n",
        "    \"\"\"Heavier tail into night hours for fraud.\"\"\"\n",
        "    if not fraud:\n",
        "        # Daytime concentration\n",
        "        probs = np.array(\n",
        "            [0.01, 0.01, 0.01, 0.01, 0.02, 0.02,  # 0-5\n",
        "             0.03, 0.04, 0.06, 0.08, 0.10, 0.10,  # 6-11\n",
        "             0.09, 0.08, 0.07, 0.06, 0.05, 0.04,  # 12-17\n",
        "             0.04, 0.03, 0.02, 0.01, 0.01, 0.01]  # 18-23\n",
        "        )\n",
        "    else:\n",
        "        # More weight to late night + high traffic ecom times\n",
        "        probs = np.array(\n",
        "            [0.06, 0.06, 0.05, 0.05, 0.05, 0.04,  # 0-5\n",
        "             0.03, 0.03, 0.03, 0.04, 0.05, 0.05,  # 6-11\n",
        "             0.05, 0.05, 0.05, 0.05, 0.04, 0.03,  # 12-17\n",
        "             0.03, 0.02, 0.02, 0.01, 0.01, 0.01]  # 18-23\n",
        "        )\n",
        "    probs /= probs.sum()\n",
        "    return np.random.choice(np.arange(24), size=size, p=probs)\n",
        "\n",
        "\n",
        "def sample_amounts(size, fraud=False):\n",
        "    \"\"\"Smaller values for good, heavier right tail for fraud.\"\"\"\n",
        "    if not fraud:\n",
        "        # Log-normal ~ median ~ 1k, mostly under 50k\n",
        "        base = np.random.lognormal(mean=8, sigma=0.6, size=size)\n",
        "    else:\n",
        "        # Heavier tail, more extreme large values\n",
        "        base = np.random.lognormal(mean=9, sigma=1.0, size=size)\n",
        "    # Cap at some upper bound\n",
        "    return np.clip(base, 10, 2_000_000)\n",
        "\n",
        "\n",
        "def sample_channels(size, fraud=False):\n",
        "    if not fraud:\n",
        "        probs = np.array(\n",
        "            [\n",
        "                0.20,  # Mobile App\n",
        "                0.10,  # NetBanking\n",
        "                0.15,  # ATM\n",
        "                0.15,  # POS\n",
        "                0.10,  # Online Purchase\n",
        "                0.15,  # UPI\n",
        "                0.05,  # Credit Card\n",
        "                0.05,  # Debit Card\n",
        "                0.05,  # Branch\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        # More fraud in ecom / card / netbanking / ATM night usage\n",
        "        probs = np.array(\n",
        "            [\n",
        "                0.18,  # Mobile App\n",
        "                0.15,  # NetBanking\n",
        "                0.10,  # ATM\n",
        "                0.08,  # POS\n",
        "                0.24,  # Online Purchase\n",
        "                0.10,  # UPI\n",
        "                0.10,  # Credit Card\n",
        "                0.03,  # Debit Card\n",
        "                0.02,  # Branch\n",
        "            ]\n",
        "        )\n",
        "    probs /= probs.sum()\n",
        "    return np.random.choice(CHANNELS, size=size, p=probs)\n",
        "\n",
        "\n",
        "def sample_locations(size, fraud=False):\n",
        "    if not fraud:\n",
        "        probs = np.array(\n",
        "            [0.18, 0.16, 0.18, 0.15, 0.13, 0.10, 0.07]  # normal cities\n",
        "            + [0.01, 0.01, 0.01, 0.01]  # high-risk rare\n",
        "        )\n",
        "    else:\n",
        "        probs = np.array(\n",
        "            [0.10, 0.10, 0.10, 0.10, 0.08, 0.07, 0.05]  # normal\n",
        "            + [0.10, 0.10, 0.10, 0.10]  # high-risk more frequent\n",
        "        )\n",
        "    probs /= probs.sum()\n",
        "    return np.random.choice(ALL_CITIES, size=size, p=probs)\n",
        "\n",
        "\n",
        "def sample_countries(size, fraud=False):\n",
        "    if not fraud:\n",
        "        probs = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0])\n",
        "    else:\n",
        "        probs = np.array([0.4, 0.1, 0.1, 0.2, 0.1, 0.1])\n",
        "    probs /= probs.sum()\n",
        "    all_countries = COUNTRIES_NORMAL + COUNTRIES_HIGH_RISK\n",
        "    return np.random.choice(all_countries, size=size, p=probs)\n",
        "\n",
        "\n",
        "def sample_txn_type(size, fraud=False):\n",
        "    if not fraud:\n",
        "        probs = np.array([0.65, 0.10, 0.15, 0.10])\n",
        "    else:\n",
        "        # more transfers and withdrawals in fraud\n",
        "        probs = np.array([0.40, 0.30, 0.20, 0.10])\n",
        "    probs /= probs.sum()\n",
        "    return np.random.choice(TRANSACTION_TYPES, size=size, p=probs)\n",
        "\n",
        "\n",
        "def sample_device_ids(size):\n",
        "    return np.random.choice(DEVICES, size=size)\n",
        "\n",
        "\n",
        "def generate_boolean(size, p_true):\n",
        "    return np.random.rand(size) < p_true\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Cell 3: Generate synthetic dataset (500k rows, ~50% fraud)\n",
        "# ============================================\n",
        "\n",
        "N_TOTAL = 500_000\n",
        "N_FRAUD = N_TOTAL // 2\n",
        "N_GOOD = N_TOTAL - N_FRAUD\n",
        "\n",
        "print(f\"Generating synthetic dataset: {N_TOTAL} rows (~50% fraud)\")\n",
        "\n",
        "# --------- GOOD (non-fraud) ----------\n",
        "good_amount = sample_amounts(N_GOOD, fraud=False)\n",
        "good_channel = sample_channels(N_GOOD, fraud=False)\n",
        "good_location = sample_locations(N_GOOD, fraud=False)\n",
        "good_txn_type = sample_txn_type(N_GOOD, fraud=False)\n",
        "good_hour = sample_hours(N_GOOD, fraud=False)\n",
        "good_dow = np.random.randint(0, 7, size=N_GOOD)  # 0=Mon\n",
        "good_month = np.random.randint(1, 13, size=N_GOOD)\n",
        "good_device = sample_device_ids(N_GOOD)\n",
        "good_home_country = sample_countries(N_GOOD, fraud=False)\n",
        "good_txn_country = good_home_country.copy()\n",
        "\n",
        "good_ip_risk = np.random.normal(loc=20, scale=10, size=N_GOOD)  # mostly low\n",
        "good_ip_risk = np.clip(good_ip_risk, 0, 100)\n",
        "\n",
        "good_vpn = generate_boolean(N_GOOD, p_true=0.02)\n",
        "good_new_device = generate_boolean(N_GOOD, p_true=0.05)\n",
        "good_new_benef = generate_boolean(N_GOOD, p_true=0.05)\n",
        "\n",
        "# txns last 1h small\n",
        "good_txns_1h = np.random.poisson(lam=1.0, size=N_GOOD)\n",
        "\n",
        "# --------- FRAUD ----------\n",
        "fraud_amount = sample_amounts(N_FRAUD, fraud=True)\n",
        "fraud_channel = sample_channels(N_FRAUD, fraud=True)\n",
        "fraud_location = sample_locations(N_FRAUD, fraud=True)\n",
        "fraud_txn_type = sample_txn_type(N_FRAUD, fraud=True)\n",
        "fraud_hour = sample_hours(N_FRAUD, fraud=True)\n",
        "fraud_dow = np.random.randint(0, 7, size=N_FRAUD)\n",
        "fraud_month = np.random.randint(1, 13, size=N_FRAUD)\n",
        "fraud_device = sample_device_ids(N_FRAUD)\n",
        "\n",
        "fraud_home_country = sample_countries(N_FRAUD, fraud=False)\n",
        "fraud_txn_country = sample_countries(N_FRAUD, fraud=True)\n",
        "\n",
        "fraud_ip_risk = np.random.normal(loc=70, scale=15, size=N_FRAUD)\n",
        "fraud_ip_risk = np.clip(fraud_ip_risk, 0, 100)\n",
        "\n",
        "fraud_vpn = generate_boolean(N_FRAUD, p_true=0.30)\n",
        "fraud_new_device = generate_boolean(N_FRAUD, p_true=0.40)\n",
        "fraud_new_benef = generate_boolean(N_FRAUD, p_true=0.35)\n",
        "\n",
        "fraud_txns_1h = np.random.poisson(lam=5.0, size=N_FRAUD)\n",
        "\n",
        "# Inject card-testing patterns: small amounts but high velocity in card channels\n",
        "card_like_mask = np.isin(fraud_channel, [\"Credit Card\", \"Debit Card\", \"Online Purchase\", \"POS\"])\n",
        "idx_card = np.where(card_like_mask)[0]\n",
        "n_card_test = int(0.15 * len(idx_card))\n",
        "card_test_idx = np.random.choice(idx_card, size=n_card_test, replace=False)\n",
        "fraud_amount[card_test_idx] = np.random.uniform(10, 200, size=n_card_test)\n",
        "fraud_txns_1h[card_test_idx] = np.random.randint(5, 15, size=n_card_test)\n",
        "\n",
        "# Assemble GOOD df\n",
        "good_df = pd.DataFrame(\n",
        "    {\n",
        "        \"Amount\": good_amount,\n",
        "        \"TransactionType\": good_txn_type,\n",
        "        \"Location\": good_location,\n",
        "        \"DeviceID\": good_device,\n",
        "        \"Channel\": good_channel,\n",
        "        \"hour\": good_hour,\n",
        "        \"day_of_week\": good_dow,\n",
        "        \"month\": good_month,\n",
        "        # extra / rule-features\n",
        "        \"ip_risk_score\": good_ip_risk,\n",
        "        \"vpn_detected\": good_vpn.astype(int),\n",
        "        \"new_device\": good_new_device.astype(int),\n",
        "        \"new_beneficiary\": good_new_benef.astype(int),\n",
        "        \"txns_last_1h\": good_txns_1h,\n",
        "        \"home_country\": good_home_country,\n",
        "        \"txn_country\": good_txn_country,\n",
        "        \"Label\": 0,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Assemble FRAUD df\n",
        "fraud_df = pd.DataFrame(\n",
        "    {\n",
        "        \"Amount\": fraud_amount,\n",
        "        \"TransactionType\": fraud_txn_type,\n",
        "        \"Location\": fraud_location,\n",
        "        \"DeviceID\": fraud_device,\n",
        "        \"Channel\": fraud_channel,\n",
        "        \"hour\": fraud_hour,\n",
        "        \"day_of_week\": fraud_dow,\n",
        "        \"month\": fraud_month,\n",
        "        # extra / rule-features\n",
        "        \"ip_risk_score\": fraud_ip_risk,\n",
        "        \"vpn_detected\": fraud_vpn.astype(int),\n",
        "        \"new_device\": fraud_new_device.astype(int),\n",
        "        \"new_beneficiary\": fraud_new_benef.astype(int),\n",
        "        \"txns_last_1h\": fraud_txns_1h,\n",
        "        \"home_country\": fraud_home_country,\n",
        "        \"txn_country\": fraud_txn_country,\n",
        "        \"Label\": 1,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Concatenate & shuffle\n",
        "all_df = pd.concat([good_df, fraud_df], ignore_index=True)\n",
        "all_df = all_df.sample(frac=1.0, random_state=RANDOM_STATE).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n=== Synthetic dataset summary ===\")\n",
        "print(all_df[\"Label\"].value_counts())\n",
        "print(\"Fraud rate:\", all_df[\"Label\"].mean())\n",
        "print(\"Shape:\", all_df.shape)\n",
        "print(\"Columns:\", list(all_df.columns))\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Cell 4: Train/test split + features for ML\n",
        "# ============================================\n",
        "\n",
        "# 8 core features used by app + fraud_logic.py for ML\n",
        "FEATURES_FOR_MODEL = [\n",
        "    \"Amount\",\n",
        "    \"TransactionType\",\n",
        "    \"Location\",\n",
        "    \"DeviceID\",\n",
        "    \"Channel\",\n",
        "    \"hour\",\n",
        "    \"day_of_week\",\n",
        "    \"month\",\n",
        "]\n",
        "\n",
        "X = all_df[FEATURES_FOR_MODEL].copy()\n",
        "y = all_df[\"Label\"].astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.25,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Cell 5: Preprocessing builder\n",
        "# ============================================\n",
        "\n",
        "def make_preprocess():\n",
        "    \"\"\"\n",
        "    Create a fresh ColumnTransformer with OneHotEncoder for categorical\n",
        "    features, numeric passthrough for others.\n",
        "    This must NEVER be re-fitted outside its own pipeline.\n",
        "    \"\"\"\n",
        "    categorical_features = [\"TransactionType\", \"Location\", \"DeviceID\", \"Channel\"]\n",
        "    numeric_features = [\"Amount\", \"hour\", \"day_of_week\", \"month\"]\n",
        "\n",
        "    # Use sparse_output if sklearn >=1.2, else fallback to sparse=True\n",
        "    try:\n",
        "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
        "    except TypeError:\n",
        "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"cat\", ohe, categorical_features),\n",
        "            (\"num\", \"passthrough\", numeric_features),\n",
        "        ],\n",
        "        remainder=\"drop\",\n",
        "    )\n",
        "    return preprocessor\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Cell 6: Train LightGBM supervised pipeline\n",
        "# ============================================\n",
        "\n",
        "print(\"\\nFitting LightGBM supervised pipeline...\")\n",
        "\n",
        "preprocess_supervised = make_preprocess()\n",
        "\n",
        "supervised_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocess_supervised),\n",
        "        (\n",
        "            \"model\",\n",
        "            LGBMClassifier(\n",
        "                n_estimators=150,\n",
        "                learning_rate=0.05,\n",
        "                max_depth=-1,\n",
        "                num_leaves=31,\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.8,\n",
        "                random_state=RANDOM_STATE,\n",
        "                n_jobs=-1,\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "supervised_pipeline.fit(X_train, y_train)\n",
        "print(\"Done.\")\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"\\nPredicting fraud probabilities on test set...\")\n",
        "y_proba = supervised_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Prob range:\", y_proba.min(), \"‚Üí\", y_proba.max())\n",
        "roc = roc_auc_score(y_test, y_proba)\n",
        "pr_auc = average_precision_score(y_test, y_proba)\n",
        "print(\"ROC AUC:\", roc)\n",
        "print(\"PR AUC :\", pr_auc)\n",
        "\n",
        "prec, rec, thr = precision_recall_curve(y_test, y_proba)\n",
        "f1 = 2 * (prec * rec) / (prec + rec + 1e-9)\n",
        "best_idx = np.argmax(f1)\n",
        "best_threshold_supervised = thr[best_idx]\n",
        "\n",
        "print(\"\\n=== Optimal LightGBM Threshold ===\")\n",
        "print(\"Threshold:\", best_threshold_supervised)\n",
        "print(\"Precision:\", prec[best_idx])\n",
        "print(\"Recall   :\", rec[best_idx])\n",
        "print(\"F1 score :\", f1[best_idx])\n",
        "\n",
        "y_pred_supervised = (y_proba >= best_threshold_supervised).astype(int)\n",
        "print(\"\\nClassification report (LightGBM @ optimal threshold):\")\n",
        "print(classification_report(y_test, y_pred_supervised))\n",
        "\n",
        "print(\"Confusion matrix (LightGBM):\")\n",
        "print(confusion_matrix(y_test, y_pred_supervised))\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Cell 7: Train IsolationForest pipeline\n",
        "# ============================================\n",
        "\n",
        "print(\"\\nTraining IsolationForest (anomaly model)...\")\n",
        "\n",
        "# Only non-fraud samples for IForest training\n",
        "X_train_nonfraud = X_train[y_train == 0]\n",
        "\n",
        "preprocess_iforest = make_preprocess()\n",
        "\n",
        "iforest = IsolationForest(\n",
        "    n_estimators=150,\n",
        "    contamination=0.10,  # expected fraud-ish fraction\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "iforest_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocess_iforest),\n",
        "        (\"iforest\", iforest),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Fitting IsolationForest pipeline...\")\n",
        "iforest_pipeline.fit(X_train_nonfraud)\n",
        "print(\"Done.\")\n",
        "\n",
        "print(\"\\nScoring anomaly on test set...\")\n",
        "anomaly_raw = iforest_pipeline.decision_function(X_test)\n",
        "anomaly_score = -anomaly_raw  # higher => more anomalous\n",
        "\n",
        "print(\"Anomaly score range:\", anomaly_score.min(), \"‚Üí\", anomaly_score.max())\n",
        "\n",
        "prec_if, rec_if, thr_if = precision_recall_curve(y_test, anomaly_score)\n",
        "f1_if = 2 * (prec_if * rec_if) / (prec_if + rec_if + 1e-9)\n",
        "best_idx_if = np.argmax(f1_if)\n",
        "threshold_iforest = thr_if[best_idx_if]\n",
        "\n",
        "print(\"\\n=== Optimal IsolationForest Threshold ===\")\n",
        "print(\"Threshold:\", threshold_iforest)\n",
        "print(\"Precision:\", prec_if[best_idx_if])\n",
        "print(\"Recall   :\", rec_if[best_idx_if])\n",
        "print(\"F1 score :\", f1_if[best_idx_if])\n",
        "\n",
        "y_pred_if = (anomaly_score >= threshold_iforest).astype(int)\n",
        "\n",
        "print(\"\\nClassification report (IForest @ optimal threshold):\")\n",
        "print(classification_report(y_test, y_pred_if))\n",
        "\n",
        "print(\"Confusion matrix (IForest):\")\n",
        "print(confusion_matrix(y_test, y_pred_if))\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Cell 8: Combined model evaluation (OR logic)\n",
        "# ============================================\n",
        "\n",
        "y_pred_combined = np.where(\n",
        "    (y_pred_supervised == 1) | (y_pred_if == 1),\n",
        "    1,\n",
        "    0,\n",
        ")\n",
        "\n",
        "print(\"\\n=== Final Combined Model Report (OR: supervised OR anomaly) ===\")\n",
        "print(classification_report(y_test, y_pred_combined))\n",
        "print(\"Confusion matrix (combined):\")\n",
        "print(confusion_matrix(y_test, y_pred_combined))\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Cell 9: Save models & thresholds\n",
        "# ============================================\n",
        "\n",
        "joblib.dump(supervised_pipeline, supervised_path)\n",
        "joblib.dump(iforest_pipeline, iforest_path)\n",
        "\n",
        "thresholds = {\n",
        "    \"supervised_threshold\": float(best_threshold_supervised),\n",
        "    \"iforest_threshold\": float(threshold_iforest),\n",
        "}\n",
        "\n",
        "with open(thresholds_path, \"w\") as f:\n",
        "    json.dump(thresholds, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved:\")\n",
        "print(\" -\", supervised_path)\n",
        "print(\" -\", iforest_path)\n",
        "print(\" -\", thresholds_path)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Cell 10: Compatibility checker (non-intrusive)\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\\n======================================\")\n",
        "print(\"üîç MODEL COMPATIBILITY CHECK STARTED\")\n",
        "print(\"======================================\")\n",
        "\n",
        "sup_loaded = joblib.load(supervised_path)\n",
        "\n",
        "if not hasattr(sup_loaded, \"feature_names_in_\"):\n",
        "    raise RuntimeError(\n",
        "        \"Supervised pipeline has no 'feature_names_in_'. \"\n",
        "        \"It must be trained with a pandas DataFrame.\"\n",
        "    )\n",
        "\n",
        "trained_features = list(sup_loaded.feature_names_in_)\n",
        "print(\"\\n‚úî Pipeline trained features:\", len(trained_features))\n",
        "print(trained_features)\n",
        "\n",
        "print(\"\\n‚úî Expected app features:\", len(FEATURES_FOR_MODEL))\n",
        "print(FEATURES_FOR_MODEL)\n",
        "\n",
        "missing = set(FEATURES_FOR_MODEL) - set(trained_features)\n",
        "extra = set(trained_features) - set(FEATURES_FOR_MODEL)\n",
        "\n",
        "if missing:\n",
        "    print(\"\\n‚ùå Missing expected app features in pipeline:\", missing)\n",
        "else:\n",
        "    print(\"\\n‚úÖ No missing app features in pipeline.\")\n",
        "\n",
        "if extra:\n",
        "    print(\"‚ö† Extra features in pipeline (app ignore):\", extra)\n",
        "else:\n",
        "    print(\"‚úÖ No extra features in pipeline.\")\n",
        "\n",
        "\n",
        "def check_internal_alignment(pipeline):\n",
        "    \"\"\"\n",
        "    Ensure preprocess & model have consistent transformed feature dimension.\n",
        "    No .fit() is called here ‚Äì only .transform() on a dummy row.\n",
        "    \"\"\"\n",
        "    if \"preprocess\" not in pipeline.named_steps:\n",
        "        print(\"\\n‚ùå No 'preprocess' step in pipeline.\")\n",
        "        return False\n",
        "\n",
        "    # assume last step is model\n",
        "    model_step = list(pipeline.named_steps.values())[-1]\n",
        "    if not hasattr(model_step, \"n_features_in_\"):\n",
        "        print(\"\\n‚ùå Model has no 'n_features_in_' attribute.\")\n",
        "        return False\n",
        "\n",
        "    # dummy row\n",
        "    dummy = pd.DataFrame(\n",
        "        [\n",
        "            {\n",
        "                \"Amount\": 1000.0,\n",
        "                \"TransactionType\": \"PAYMENT\",\n",
        "                \"Location\": \"Mumbai\",\n",
        "                \"DeviceID\": \"MOB-ANDROID\",\n",
        "                \"Channel\": \"Mobile App\",\n",
        "                \"hour\": 12,\n",
        "                \"day_of_week\": 2,\n",
        "                \"month\": 5,\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    dummy = dummy.reindex(columns=trained_features)\n",
        "\n",
        "    preprocess = pipeline.named_steps[\"preprocess\"]\n",
        "    Z = preprocess.transform(dummy)\n",
        "\n",
        "    if hasattr(Z, \"shape\"):\n",
        "        n_transformed = Z.shape[1]\n",
        "    else:\n",
        "        print(\"\\n‚ùå Could not read transformed shape.\")\n",
        "        return False\n",
        "\n",
        "    n_expected = int(model_step.n_features_in_)\n",
        "\n",
        "    print(f\"\\n‚úî Preprocess produces {n_transformed} features.\")\n",
        "    print(f\"‚úî Model expects     {n_expected} features.\")\n",
        "\n",
        "    if n_transformed != n_expected:\n",
        "        print(\n",
        "            \"\\n‚ùå INTERNAL MISMATCH: preprocessor and model disagree on feature count.\\n\"\n",
        "            \"   ‚ûú This pipeline would be unsafe for inference.\\n\"\n",
        "            \"   Re-run training cleanly if you see this.\"\n",
        "        )\n",
        "        return False\n",
        "\n",
        "    print(\"\\n‚úÖ Internal alignment OK.\")\n",
        "    return True\n",
        "\n",
        "\n",
        "alignment_ok = check_internal_alignment(sup_loaded)\n",
        "\n",
        "print(\"\\n======================================\")\n",
        "print(\"üîç MODEL COMPATIBILITY CHECK FINISHED\")\n",
        "print(\"======================================\\n\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Cell 11: Final inference examples (safe)\n",
        "# ============================================\n",
        "\n",
        "if not alignment_ok:\n",
        "    print(\n",
        "        \"üö´ Skipping example scoring because pipeline is inconsistent.\\n\"\n",
        "        \"   Re-run training cells from top if this happens.\"\n",
        "    )\n",
        "else:\n",
        "    print(\"Reloading models for inference test...\")\n",
        "    iforest_loaded = joblib.load(iforest_path)\n",
        "    with open(thresholds_path, \"r\") as f:\n",
        "        th_loaded = json.load(f)\n",
        "\n",
        "    th_sup = float(th_loaded[\"supervised_threshold\"])\n",
        "    th_if = float(th_loaded[\"iforest_threshold\"])\n",
        "\n",
        "    print(\"Loaded thresholds:\")\n",
        "    print(\"  Supervised     :\", th_sup)\n",
        "    print(\"  IsolationForest:\", th_if)\n",
        "\n",
        "    def score_example(sample: dict, label: str = \"Unknown\"):\n",
        "        # Fill defaults to avoid missing keys\n",
        "        base = {\n",
        "            \"Amount\": 0.0,\n",
        "            \"TransactionType\": \"PAYMENT\",\n",
        "            \"Location\": \"Unknown\",\n",
        "            \"DeviceID\": \"Unknown\",\n",
        "            \"Channel\": \"Other\",\n",
        "            \"hour\": 12,\n",
        "            \"day_of_week\": 0,\n",
        "            \"month\": 1,\n",
        "        }\n",
        "        base.update(sample)\n",
        "        df = pd.DataFrame([base])\n",
        "        df = df.reindex(columns=trained_features)\n",
        "\n",
        "        fraud_prob = float(sup_loaded.predict_proba(df)[0, 1])\n",
        "        anom_raw = float(iforest_loaded.decision_function(df)[0])\n",
        "        anom_score = -anom_raw\n",
        "\n",
        "        flag_sup = fraud_prob >= th_sup\n",
        "        flag_if = anom_score >= th_if\n",
        "        flag_combined = flag_sup or flag_if\n",
        "\n",
        "        print(\"\\n============================\")\n",
        "        print(f\"Example: {label}\")\n",
        "        print(\"============================\")\n",
        "        print(\"Input:\", base)\n",
        "        print(f\"Fraud Probability (ML): {fraud_prob:.6f}\")\n",
        "        print(f\"Anomaly Score (IForest): {anom_score:.6f}\")\n",
        "        print(f\"Supervised Flag (>= {th_sup:.4f}): {flag_sup}\")\n",
        "        print(f\"IForest Flag (>= {th_if:.4f}): {flag_if}\")\n",
        "        print(f\"Combined Fraud Flag (OR): {flag_combined}\")\n",
        "\n",
        "    # Diverse realistic examples\n",
        "    examples = [\n",
        "        (\n",
        "            {\n",
        "                \"Amount\": 800.0,\n",
        "                \"TransactionType\": \"PAYMENT\",\n",
        "                \"Location\": \"Mumbai\",\n",
        "                \"DeviceID\": \"MOB-ANDROID\",\n",
        "                \"Channel\": \"Mobile App\",\n",
        "                \"hour\": 13,\n",
        "                \"day_of_week\": 2,\n",
        "                \"month\": 5,\n",
        "            },\n",
        "            \"GOOD: small mobile-app payment (daytime)\",\n",
        "        ),\n",
        "        (\n",
        "            {\n",
        "                \"Amount\": 1200.0,\n",
        "                \"TransactionType\": \"PAYMENT\",\n",
        "                \"Location\": \"Bangalore\",\n",
        "                \"DeviceID\": \"POS-TERM-001\",\n",
        "                \"Channel\": \"POS\",\n",
        "                \"hour\": 19,\n",
        "                \"day_of_week\": 5,\n",
        "                \"month\": 8,\n",
        "            },\n",
        "            \"GOOD: evening POS grocery shopping\",\n",
        "        ),\n",
        "        (\n",
        "            {\n",
        "                \"Amount\": 6000.0,\n",
        "                \"TransactionType\": \"WITHDRAWAL\",\n",
        "                \"Location\": \"Delhi\",\n",
        "                \"DeviceID\": \"ATM-0001\",\n",
        "                \"Channel\": \"ATM\",\n",
        "                \"hour\": 11,\n",
        "                \"day_of_week\": 1,\n",
        "                \"month\": 3,\n",
        "            },\n",
        "            \"GOOD: normal ATM withdrawal weekday morning\",\n",
        "        ),\n",
        "        (\n",
        "            {\n",
        "                \"Amount\": 450000.0,\n",
        "                \"TransactionType\": \"TRANSFER\",\n",
        "                \"Location\": \"Mumbai\",\n",
        "                \"DeviceID\": \"WEB-CHROME\",\n",
        "                \"Channel\": \"NetBanking\",\n",
        "                \"hour\": 2,\n",
        "                \"day_of_week\": 1,\n",
        "                \"month\": 4,\n",
        "            },\n",
        "            \"FRAUD-LIKE: large late-night netbanking transfer\",\n",
        "        ),\n",
        "        (\n",
        "            {\n",
        "                \"Amount\": 200000.0,\n",
        "                \"TransactionType\": \"PAYMENT\",\n",
        "                \"Location\": \"Lagos\",\n",
        "                \"DeviceID\": \"WEB-CHROME\",\n",
        "                \"Channel\": \"Online Purchase\",\n",
        "                \"hour\": 1,\n",
        "                \"day_of_week\": 4,\n",
        "                \"month\": 9,\n",
        "            },\n",
        "            \"FRAUD-LIKE: high-value international online purchase at odd hour\",\n",
        "        ),\n",
        "        (\n",
        "            {\n",
        "                \"Amount\": 250000.0,\n",
        "                \"TransactionType\": \"WITHDRAWAL\",\n",
        "                \"Location\": \"Lagos\",\n",
        "                \"DeviceID\": \"ATM-0002\",\n",
        "                \"Channel\": \"ATM\",\n",
        "                \"hour\": 0,\n",
        "                \"day_of_week\": 6,\n",
        "                \"month\": 12,\n",
        "            },\n",
        "            \"FRAUD-LIKE: abnormal high ATM withdrawal at midnight in high-risk city\",\n",
        "        ),\n",
        "        (\n",
        "            {\n",
        "                \"Amount\": 150000.0,\n",
        "                \"TransactionType\": \"TRANSFER\",\n",
        "                \"Location\": \"New York\",\n",
        "                \"DeviceID\": \"WEB-CHROME\",\n",
        "                \"Channel\": \"Online Purchase\",\n",
        "                \"hour\": 23,\n",
        "                \"day_of_week\": 0,\n",
        "                \"month\": 1,\n",
        "            },\n",
        "            \"FRAUD-LIKE: cross-border high-value online transfer/purchase\",\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    for sample, label in examples:\n",
        "        score_example(sample, label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noA4640OyNYL",
        "outputId": "672c04d1-966e-428c-9ad9-00ac61b0158e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating synthetic dataset: 500000 rows (~50% fraud)\n",
            "\n",
            "=== Synthetic dataset summary ===\n",
            "Label\n",
            "0    250000\n",
            "1    250000\n",
            "Name: count, dtype: int64\n",
            "Fraud rate: 0.5\n",
            "Shape: (500000, 16)\n",
            "Columns: ['Amount', 'TransactionType', 'Location', 'DeviceID', 'Channel', 'hour', 'day_of_week', 'month', 'ip_risk_score', 'vpn_detected', 'new_device', 'new_beneficiary', 'txns_last_1h', 'home_country', 'txn_country', 'Label']\n",
            "\n",
            "Train shape: (375000, 8) Test shape: (125000, 8)\n",
            "\n",
            "Fitting LightGBM supervised pipeline...\n",
            "[LightGBM] [Info] Number of positive: 187500, number of negative: 187500\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014968 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 365\n",
            "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 37\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Done.\n",
            "\n",
            "Predicting fraud probabilities on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prob range: 0.030671159072950493 ‚Üí 0.9994412219633907\n",
            "ROC AUC: 0.9237044768000001\n",
            "PR AUC : 0.9359408446580543\n",
            "\n",
            "=== Optimal LightGBM Threshold ===\n",
            "Threshold: 0.4303858140504603\n",
            "Precision: 0.8533547153918424\n",
            "Recall   : 0.842896\n",
            "F1 score : 0.8480931141063264\n",
            "\n",
            "Classification report (LightGBM @ optimal threshold):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85     62500\n",
            "           1       0.85      0.84      0.85     62500\n",
            "\n",
            "    accuracy                           0.85    125000\n",
            "   macro avg       0.85      0.85      0.85    125000\n",
            "weighted avg       0.85      0.85      0.85    125000\n",
            "\n",
            "Confusion matrix (LightGBM):\n",
            "[[53447  9053]\n",
            " [ 9819 52681]]\n",
            "\n",
            "Training IsolationForest (anomaly model)...\n",
            "Fitting IsolationForest pipeline...\n",
            "Done.\n",
            "\n",
            "Scoring anomaly on test set...\n",
            "Anomaly score range: -0.07975537051591236 ‚Üí 0.09058830480506286\n",
            "\n",
            "=== Optimal IsolationForest Threshold ===\n",
            "Threshold: -0.03897585500238099\n",
            "Precision: 0.6387116585349211\n",
            "Recall   : 0.89856\n",
            "F1 score : 0.7466744661991231\n",
            "\n",
            "Classification report (IForest @ optimal threshold):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.49      0.62     62500\n",
            "           1       0.64      0.90      0.75     62500\n",
            "\n",
            "    accuracy                           0.70    125000\n",
            "   macro avg       0.73      0.70      0.68    125000\n",
            "weighted avg       0.73      0.70      0.68    125000\n",
            "\n",
            "Confusion matrix (IForest):\n",
            "[[30733 31767]\n",
            " [ 6340 56160]]\n",
            "\n",
            "=== Final Combined Model Report (OR: supervised OR anomaly) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.47      0.62     62500\n",
            "           1       0.64      0.94      0.76     62500\n",
            "\n",
            "    accuracy                           0.70    125000\n",
            "   macro avg       0.76      0.70      0.69    125000\n",
            "weighted avg       0.76      0.70      0.69    125000\n",
            "\n",
            "Confusion matrix (combined):\n",
            "[[29547 32953]\n",
            " [ 4020 58480]]\n",
            "\n",
            "Saved:\n",
            " - models/supervised_lgbm_pipeline.joblib\n",
            " - models/iforest_pipeline.joblib\n",
            " - models/model_thresholds.json\n",
            "\n",
            "\n",
            "======================================\n",
            "üîç MODEL COMPATIBILITY CHECK STARTED\n",
            "======================================\n",
            "\n",
            "‚úî Pipeline trained features: 8\n",
            "['Amount', 'TransactionType', 'Location', 'DeviceID', 'Channel', 'hour', 'day_of_week', 'month']\n",
            "\n",
            "‚úî Expected app features: 8\n",
            "['Amount', 'TransactionType', 'Location', 'DeviceID', 'Channel', 'hour', 'day_of_week', 'month']\n",
            "\n",
            "‚úÖ No missing app features in pipeline.\n",
            "‚úÖ No extra features in pipeline.\n",
            "\n",
            "‚úî Preprocess produces 37 features.\n",
            "‚úî Model expects     37 features.\n",
            "\n",
            "‚úÖ Internal alignment OK.\n",
            "\n",
            "======================================\n",
            "üîç MODEL COMPATIBILITY CHECK FINISHED\n",
            "======================================\n",
            "\n",
            "Reloading models for inference test...\n",
            "Loaded thresholds:\n",
            "  Supervised     : 0.4303858140504603\n",
            "  IsolationForest: -0.03897585500238099\n",
            "\n",
            "============================\n",
            "Example: GOOD: small mobile-app payment (daytime)\n",
            "============================\n",
            "Input: {'Amount': 800.0, 'TransactionType': 'PAYMENT', 'Location': 'Mumbai', 'DeviceID': 'MOB-ANDROID', 'Channel': 'Mobile App', 'hour': 13, 'day_of_week': 2, 'month': 5}\n",
            "Fraud Probability (ML): 0.086325\n",
            "Anomaly Score (IForest): -0.058364\n",
            "Supervised Flag (>= 0.4304): False\n",
            "IForest Flag (>= -0.0390): False\n",
            "Combined Fraud Flag (OR): False\n",
            "\n",
            "============================\n",
            "Example: GOOD: evening POS grocery shopping\n",
            "============================\n",
            "Input: {'Amount': 1200.0, 'TransactionType': 'PAYMENT', 'Location': 'Bangalore', 'DeviceID': 'POS-TERM-001', 'Channel': 'POS', 'hour': 19, 'day_of_week': 5, 'month': 8}\n",
            "Fraud Probability (ML): 0.054230\n",
            "Anomaly Score (IForest): -0.032143\n",
            "Supervised Flag (>= 0.4304): False\n",
            "IForest Flag (>= -0.0390): True\n",
            "Combined Fraud Flag (OR): True\n",
            "\n",
            "============================\n",
            "Example: GOOD: normal ATM withdrawal weekday morning\n",
            "============================\n",
            "Input: {'Amount': 6000.0, 'TransactionType': 'WITHDRAWAL', 'Location': 'Delhi', 'DeviceID': 'ATM-0001', 'Channel': 'ATM', 'hour': 11, 'day_of_week': 1, 'month': 3}\n",
            "Fraud Probability (ML): 0.228215\n",
            "Anomaly Score (IForest): -0.021463\n",
            "Supervised Flag (>= 0.4304): False\n",
            "IForest Flag (>= -0.0390): True\n",
            "Combined Fraud Flag (OR): True\n",
            "\n",
            "============================\n",
            "Example: FRAUD-LIKE: large late-night netbanking transfer\n",
            "============================\n",
            "Input: {'Amount': 450000.0, 'TransactionType': 'TRANSFER', 'Location': 'Mumbai', 'DeviceID': 'WEB-CHROME', 'Channel': 'NetBanking', 'hour': 2, 'day_of_week': 1, 'month': 4}\n",
            "Fraud Probability (ML): 0.999122\n",
            "Anomaly Score (IForest): 0.040975\n",
            "Supervised Flag (>= 0.4304): True\n",
            "IForest Flag (>= -0.0390): True\n",
            "Combined Fraud Flag (OR): True\n",
            "\n",
            "============================\n",
            "Example: FRAUD-LIKE: high-value international online purchase at odd hour\n",
            "============================\n",
            "Input: {'Amount': 200000.0, 'TransactionType': 'PAYMENT', 'Location': 'Lagos', 'DeviceID': 'WEB-CHROME', 'Channel': 'Online Purchase', 'hour': 1, 'day_of_week': 4, 'month': 9}\n",
            "Fraud Probability (ML): 0.999318\n",
            "Anomaly Score (IForest): 0.002992\n",
            "Supervised Flag (>= 0.4304): True\n",
            "IForest Flag (>= -0.0390): True\n",
            "Combined Fraud Flag (OR): True\n",
            "\n",
            "============================\n",
            "Example: FRAUD-LIKE: abnormal high ATM withdrawal at midnight in high-risk city\n",
            "============================\n",
            "Input: {'Amount': 250000.0, 'TransactionType': 'WITHDRAWAL', 'Location': 'Lagos', 'DeviceID': 'ATM-0002', 'Channel': 'ATM', 'hour': 0, 'day_of_week': 6, 'month': 12}\n",
            "Fraud Probability (ML): 0.999301\n",
            "Anomaly Score (IForest): 0.058535\n",
            "Supervised Flag (>= 0.4304): True\n",
            "IForest Flag (>= -0.0390): True\n",
            "Combined Fraud Flag (OR): True\n",
            "\n",
            "============================\n",
            "Example: FRAUD-LIKE: cross-border high-value online transfer/purchase\n",
            "============================\n",
            "Input: {'Amount': 150000.0, 'TransactionType': 'TRANSFER', 'Location': 'New York', 'DeviceID': 'WEB-CHROME', 'Channel': 'Online Purchase', 'hour': 23, 'day_of_week': 0, 'month': 1}\n",
            "Fraud Probability (ML): 0.999023\n",
            "Anomaly Score (IForest): 0.009546\n",
            "Supervised Flag (>= 0.4304): True\n",
            "IForest Flag (>= -0.0390): True\n",
            "Combined Fraud Flag (OR): True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Cell 11 (FINAL FIXED): Clean example inference\n",
        "# =========================================================\n",
        "\n",
        "print(\"Reloading models for inference test...\")\n",
        "\n",
        "# Suppress LightGBM feature-name warnings\n",
        "import lightgbm\n",
        "lightgbm.LGBMClassifier._warn_for_feature_names = lambda *args, **kwargs: None\n",
        "\n",
        "sup_loaded = joblib.load(supervised_path)\n",
        "iforest_loaded = joblib.load(iforest_path)\n",
        "with open(thresholds_path, \"r\") as f:\n",
        "    th_loaded = json.load(f)\n",
        "\n",
        "th_sup = float(th_loaded[\"supervised_threshold\"])\n",
        "th_if = float(th_loaded[\"iforest_threshold\"])\n",
        "\n",
        "# ----------------------------------------------\n",
        "# NEW: Conservative IForest threshold\n",
        "# Reduce false positives drastically\n",
        "# ----------------------------------------------\n",
        "\n",
        "# We drop IForest to only flag ~2% worst anomalies\n",
        "# (much safer for real-time fraud systems)\n",
        "\n",
        "print(\"\\nRecalibrating IsolationForest threshold...\")\n",
        "# Score anomaly only once\n",
        "example_anom = -iforest_loaded.decision_function(X_test[:50000])\n",
        "new_if_threshold = np.percentile(example_anom, 98)   # top 2%\n",
        "\n",
        "print(\"Original threshold:\", th_if)\n",
        "print(\"Revised safer threshold:\", new_if_threshold)\n",
        "\n",
        "th_if = float(new_if_threshold)\n",
        "\n",
        "\n",
        "# ----------------------------------------------\n",
        "# Safe scoring function\n",
        "# ----------------------------------------------\n",
        "def score_example(sample: dict, label: str = \"Unknown\"):\n",
        "    \"\"\"Safe inference guaranteed without warnings or feature mismatch.\"\"\"\n",
        "\n",
        "    base = {\n",
        "        \"Amount\": 0.0,\n",
        "        \"TransactionType\": \"PAYMENT\",\n",
        "        \"Location\": \"Unknown\",\n",
        "        \"DeviceID\": \"Unknown\",\n",
        "        \"Channel\": \"Other\",\n",
        "        \"hour\": 12,\n",
        "        \"day_of_week\": 0,\n",
        "        \"month\": 1,\n",
        "    }\n",
        "    base.update(sample)\n",
        "\n",
        "    df = pd.DataFrame([base])\n",
        "    df = df.reindex(columns=sup_loaded.feature_names_in_)\n",
        "\n",
        "    # ML prediction\n",
        "    fraud_prob = float(sup_loaded.predict_proba(df)[0, 1])\n",
        "\n",
        "    # Anomaly score\n",
        "    anom_score = float(-iforest_loaded.decision_function(df)[0])\n",
        "\n",
        "    # Flags\n",
        "    flag_sup = fraud_prob >= th_sup\n",
        "    flag_if = anom_score >= th_if\n",
        "    flag_combined = flag_sup or flag_if\n",
        "\n",
        "    print(\"\\n============================\")\n",
        "    print(f\"Example: {label}\")\n",
        "    print(\"============================\")\n",
        "    print(\"Input:\", base)\n",
        "    print(f\"Fraud Probability (ML): {fraud_prob:.6f}\")\n",
        "    print(f\"Anomaly Score (IForest): {anom_score:.6f}\")\n",
        "    print(f\"Supervised Flag (>= {th_sup:.4f}): {flag_sup}\")\n",
        "    print(f\"IForest Flag (>= {th_if:.4f}): {flag_if}\")\n",
        "    print(f\"Combined Fraud Flag (OR): {flag_combined}\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------\n",
        "# Test examples\n",
        "# ----------------------------------------------\n",
        "\n",
        "examples = [\n",
        "    (\n",
        "        {\n",
        "            \"Amount\": 800.0,\n",
        "            \"TransactionType\": \"PAYMENT\",\n",
        "            \"Location\": \"Mumbai\",\n",
        "            \"DeviceID\": \"MOB-ANDROID\",\n",
        "            \"Channel\": \"Mobile App\",\n",
        "            \"hour\": 13,\n",
        "            \"day_of_week\": 2,\n",
        "            \"month\": 5,\n",
        "        },\n",
        "        \"GOOD: small mobile-app payment (daytime)\",\n",
        "    ),\n",
        "    (\n",
        "        {\n",
        "            \"Amount\": 1200.0,\n",
        "            \"TransactionType\": \"PAYMENT\",\n",
        "            \"Location\": \"Bangalore\",\n",
        "            \"DeviceID\": \"POS-TERM-001\",\n",
        "            \"Channel\": \"POS\",\n",
        "            \"hour\": 19,\n",
        "            \"day_of_week\": 5,\n",
        "            \"month\": 8,\n",
        "        },\n",
        "        \"GOOD: POS grocery shopping\",\n",
        "    ),\n",
        "    (\n",
        "        {\n",
        "            \"Amount\": 6000.0,\n",
        "            \"TransactionType\": \"WITHDRAWAL\",\n",
        "            \"Location\": \"Delhi\",\n",
        "            \"DeviceID\": \"ATM-0001\",\n",
        "            \"Channel\": \"ATM\",\n",
        "            \"hour\": 11,\n",
        "            \"day_of_week\": 1,\n",
        "            \"month\": 3,\n",
        "        },\n",
        "        \"GOOD: ATM weekday withdrawal\",\n",
        "    ),\n",
        "    (\n",
        "        {\n",
        "            \"Amount\": 450000.0,\n",
        "            \"TransactionType\": \"TRANSFER\",\n",
        "            \"Location\": \"Mumbai\",\n",
        "            \"DeviceID\": \"WEB-CHROME\",\n",
        "            \"Channel\": \"NetBanking\",\n",
        "            \"hour\": 2,\n",
        "            \"day_of_week\": 1,\n",
        "            \"month\": 4,\n",
        "        },\n",
        "        \"FRAUD: large night transfer\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Run examples\n",
        "for sample, label in examples:\n",
        "    score_example(sample, label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6LI4gq0y24S",
        "outputId": "0ad73abb-ea30-49a6-eb37-c4dc36e37569"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading models for inference test...\n",
            "\n",
            "Recalibrating IsolationForest threshold...\n",
            "Original threshold: -0.03897585500238099\n",
            "Revised safer threshold: 0.04069501242896777\n",
            "\n",
            "============================\n",
            "Example: GOOD: small mobile-app payment (daytime)\n",
            "============================\n",
            "Input: {'Amount': 800.0, 'TransactionType': 'PAYMENT', 'Location': 'Mumbai', 'DeviceID': 'MOB-ANDROID', 'Channel': 'Mobile App', 'hour': 13, 'day_of_week': 2, 'month': 5}\n",
            "Fraud Probability (ML): 0.086325\n",
            "Anomaly Score (IForest): -0.058364\n",
            "Supervised Flag (>= 0.4304): False\n",
            "IForest Flag (>= 0.0407): False\n",
            "Combined Fraud Flag (OR): False\n",
            "\n",
            "============================\n",
            "Example: GOOD: POS grocery shopping\n",
            "============================\n",
            "Input: {'Amount': 1200.0, 'TransactionType': 'PAYMENT', 'Location': 'Bangalore', 'DeviceID': 'POS-TERM-001', 'Channel': 'POS', 'hour': 19, 'day_of_week': 5, 'month': 8}\n",
            "Fraud Probability (ML): 0.054230\n",
            "Anomaly Score (IForest): -0.032143\n",
            "Supervised Flag (>= 0.4304): False\n",
            "IForest Flag (>= 0.0407): False\n",
            "Combined Fraud Flag (OR): False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================\n",
            "Example: GOOD: ATM weekday withdrawal\n",
            "============================\n",
            "Input: {'Amount': 6000.0, 'TransactionType': 'WITHDRAWAL', 'Location': 'Delhi', 'DeviceID': 'ATM-0001', 'Channel': 'ATM', 'hour': 11, 'day_of_week': 1, 'month': 3}\n",
            "Fraud Probability (ML): 0.228215\n",
            "Anomaly Score (IForest): -0.021463\n",
            "Supervised Flag (>= 0.4304): False\n",
            "IForest Flag (>= 0.0407): False\n",
            "Combined Fraud Flag (OR): False\n",
            "\n",
            "============================\n",
            "Example: FRAUD: large night transfer\n",
            "============================\n",
            "Input: {'Amount': 450000.0, 'TransactionType': 'TRANSFER', 'Location': 'Mumbai', 'DeviceID': 'WEB-CHROME', 'Channel': 'NetBanking', 'hour': 2, 'day_of_week': 1, 'month': 4}\n",
            "Fraud Probability (ML): 0.999122\n",
            "Anomaly Score (IForest): 0.040975\n",
            "Supervised Flag (>= 0.4304): True\n",
            "IForest Flag (>= 0.0407): True\n",
            "Combined Fraud Flag (OR): True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}